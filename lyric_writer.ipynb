{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quCUSkkjkaBq",
        "outputId": "daa4886f-6545-4843-e30d-ccea23fc4fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from unidecode import unidecode\n",
        "import random"
      ],
      "metadata": {
        "id": "9ntI8xrcYt-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "pqXtikdZZ8oV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load text"
      ],
      "metadata": {
        "id": "T_1dhvvsMqMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file=open(\"clean_lyrics_without_parenthese.txt\",\"r\")\n",
        "input=[]\n",
        "teacher_forcing=[]\n",
        "target=[]\n",
        "prev=None\n",
        "for line in file:\n",
        "  if line.startswith(\">>>\") or line.startswith(\"<sos>\") or line.startswith(\"<eos>\"):\n",
        "    continue\n",
        "  if prev==None:\n",
        "    line=unidecode(line)\n",
        "    prev=line\n",
        "  else:\n",
        "    line=unidecode(line)\n",
        "    input.append(\"<sol> \"+prev[:-1])\n",
        "    teacher_forcing.append(\"<sol> \"+line[:-1])\n",
        "    target.append(line[:-1]+\" <eol>\")\n",
        "    prev=None"
      ],
      "metadata": {
        "id": "-dm630p0di7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(input[i])\n",
        "  print(teacher_forcing[i])\n",
        "  print(target[i])\n",
        "  print(\"****\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiQhOd8lJlQ6",
        "outputId": "c31e9b91-f097-44ed-948e-eb676933dcc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> I'm doing good, I'm on some new shit\n",
            "<sol> Been saying \"yes\" instead of \"no\"\n",
            "Been saying \"yes\" instead of \"no\" <eol>\n",
            "****\n",
            "<sol> I thought I saw you at the bus stop, I didn't though\n",
            "<sol> I hit the ground running each night\n",
            "I hit the ground running each night <eol>\n",
            "****\n",
            "<sol> I hit the Sunday matinee\n",
            "<sol> You know the greatest films of all time were never made\n",
            "You know the greatest films of all time were never made <eol>\n",
            "****\n",
            "<sol> I guess you never know, never know\n",
            "<sol> And if you wanted me, you really should've showed\n",
            "And if you wanted me, you really should've showed <eol>\n",
            "****\n",
            "<sol> And if you never bleed, you're never gonna grow\n",
            "<sol> And it's alright now\n",
            "And it's alright now <eol>\n",
            "****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=list(zip(input,teacher_forcing,target))\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZLwb3p_f8OX",
        "outputId": "70fe581a-546f-4801-bacc-e417df513c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"<sol> I'm doing good, I'm on some new shit\", '<sol> Been saying \"yes\" instead of \"no\"', 'Been saying \"yes\" instead of \"no\" <eol>')\n",
            "(\"<sol> I thought I saw you at the bus stop, I didn't though\", '<sol> I hit the ground running each night', 'I hit the ground running each night <eol>')\n",
            "('<sol> I hit the Sunday matinee', '<sol> You know the greatest films of all time were never made', 'You know the greatest films of all time were never made <eol>')\n",
            "('<sol> I guess you never know, never know', \"<sol> And if you wanted me, you really should've showed\", \"And if you wanted me, you really should've showed <eol>\")\n",
            "(\"<sol> And if you never bleed, you're never gonna grow\", \"<sol> And it's alright now\", \"And it's alright now <eol>\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(corpus)\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbuCYxMagl2R",
        "outputId": "b1968a04-0903-4667-a34a-4713527e1d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('<sol> I can taste the midnight on your lips', '<sol> Makes me just wanna lean in for another kiss', 'Makes me just wanna lean in for another kiss <eol>')\n",
            "('<sol> My daddy told me: \"Slow down, boy, you\\'re goin\\' to blow it!\"', \"<sol> And I ain't gotta stop the beat a minute to tell Shady I love him\", \"And I ain't gotta stop the beat a minute to tell Shady I love him <eol>\")\n",
            "('<sol> Al final, baby, tu extranas como yo te toco', '<sol> Recuerda, de tu cuerpo se yo, mami', 'Recuerda, de tu cuerpo se yo, mami <eol>')\n",
            "('<sol> I called an old friend thinking that the trouble would wait', '<sol> But then I jumped right in a week later, returned', 'But then I jumped right in a week later, returned <eol>')\n",
            "(\"<sol> Know it's been a while, baby, a while\", '<sol> Do you still feel the fire?', 'Do you still feel the fire? <eol>')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input,teacher_forcing,target=zip(*corpus)"
      ],
      "metadata": {
        "id": "3NOut44MkwBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(input[i])\n",
        "  print(teacher_forcing[i])\n",
        "  print(target[i])\n",
        "  print(\"****\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmsOO14-xEo1",
        "outputId": "cbf5ec21-644b-4388-e642-3bacb63185d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> I can taste the midnight on your lips\n",
            "<sol> Makes me just wanna lean in for another kiss\n",
            "Makes me just wanna lean in for another kiss <eol>\n",
            "****\n",
            "<sol> My daddy told me: \"Slow down, boy, you're goin' to blow it!\"\n",
            "<sol> And I ain't gotta stop the beat a minute to tell Shady I love him\n",
            "And I ain't gotta stop the beat a minute to tell Shady I love him <eol>\n",
            "****\n",
            "<sol> Al final, baby, tu extranas como yo te toco\n",
            "<sol> Recuerda, de tu cuerpo se yo, mami\n",
            "Recuerda, de tu cuerpo se yo, mami <eol>\n",
            "****\n",
            "<sol> I called an old friend thinking that the trouble would wait\n",
            "<sol> But then I jumped right in a week later, returned\n",
            "But then I jumped right in a week later, returned <eol>\n",
            "****\n",
            "<sol> Know it's been a while, baby, a while\n",
            "<sol> Do you still feel the fire?\n",
            "Do you still feel the fire? <eol>\n",
            "****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize using text vectorization"
      ],
      "metadata": {
        "id": "f6zmv0X_ODDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lyrics contain simple words so subword tokenization seems unnecessary"
      ],
      "metadata": {
        "id": "8nK3iOZK10fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=5000\n",
        "max_length=25\n",
        "text_vec_layer=tf.keras.layers.TextVectorization(vocab_size,output_sequence_length=max_length)\n",
        "text_vec_layer.adapt(input)\n",
        "text_vec_layer.adapt(target)"
      ],
      "metadata": {
        "id": "ObysQChR1odI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=tf.constant(input[:25000])\n",
        "X_valid=tf.constant(input[25000:])\n",
        "X_train_dec=tf.constant(teacher_forcing[:25000])\n",
        "X_valid_dec=tf.constant(teacher_forcing[25000:])\n",
        "Y_train=tf.constant(target[:25000])\n",
        "Y_valid=tf.constant(target[25000:])"
      ],
      "metadata": {
        "id": "qwhlbskq5lcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vec=text_vec_layer(X_train)\n",
        "X_valid_vec=text_vec_layer(X_valid)\n",
        "X_train_dec_vec=text_vec_layer(X_train_dec)\n",
        "X_valid_dec_vec=text_vec_layer(X_valid_dec)\n",
        "Y_train_vec=text_vec_layer(Y_train)\n",
        "Y_valid_vec=text_vec_layer(Y_valid)"
      ],
      "metadata": {
        "id": "bDu2VWGa8Wm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "EaVirHUp7Xmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size=256\n",
        "embed_layer=tf.keras.layers.Embedding(vocab_size,embed_size,mask_zero=True)"
      ],
      "metadata": {
        "id": "xVUWDLXr7W8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embed=embed_layer(X_train_vec)\n",
        "X_valid_embed=embed_layer(X_valid_vec)\n",
        "X_train_dec_embed=embed_layer(X_train_dec_vec)\n",
        "X_valid_dec_embed=embed_layer(X_valid_dec_vec)"
      ],
      "metadata": {
        "id": "FZCiOC2-8VOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "ePG-p5Y6YQmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encodings"
      ],
      "metadata": {
        "id": "d9aFgG7_YKl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length,depth):\n",
        "  depth=depth/2\n",
        "\n",
        "  positions=np.arange(length)[:,np.newaxis]\n",
        "  depths=np.arange(depth)[np.newaxis,:]/depth\n",
        "\n",
        "  angle_rates=1/(10000**depths)\n",
        "  angle_rads=positions*angle_rates\n",
        "\n",
        "  positional_encoding=np.concatenate([np.sin(angle_rads),np.cos(angle_rads)],axis=-1)\n",
        "\n",
        "  return tf.cast(positional_encoding,dtype=tf.float32)"
      ],
      "metadata": {
        "id": "hR8X5ophRisS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self,vocab_size,d_model):\n",
        "    super().__init__()\n",
        "    self.d_model=d_model\n",
        "    self.embedding=tf.keras.layers.Embedding(vocab_size,d_model,mask_zero=True)\n",
        "    self.pos_encoding=positional_encoding(length=2048,depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args,**kwargs)\n",
        "\n",
        "  def call(self,tensor):\n",
        "    length=tf.shape(tensor)[1]\n",
        "    tensor=self.embedding(tensor)\n",
        "    tensor*=tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
        "    tensor+=self.pos_encoding[tf.newaxis,:length,:]\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "W0nJ2SE45FsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention layers"
      ],
      "metadata": {
        "id": "KswIPoj2FVBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self,**kwargs):\n",
        "    super().__init__()\n",
        "    self.mha=tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm=tf.keras.layers.LayerNormalization()\n",
        "    self.add=tf.keras.layers.Add()"
      ],
      "metadata": {
        "id": "IkoDF-RN_dqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self,tensor,context):\n",
        "    attention_output,attention_scores=self.mha(query=tensor,key=context,value=context,return_attention_scores=True)\n",
        "    self.last_attention_scores=attention_scores\n",
        "    tensor=self.add([tensor,attention_output])\n",
        "    tensor=self.layernorm(tensor)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "_0-F1OX9F3PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self,tensor):\n",
        "    attention_output=self.mha(query=tensor,value=tensor,key=tensor)\n",
        "    tensor=self.add([tensor,attention_output])\n",
        "    tensor=self.layernorm(tensor)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "pCubGeHTN485"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self,tensor):\n",
        "    attention_output=self.mha(query=tensor,value=tensor,key=tensor,use_causal_mask=True)\n",
        "    tensor=self.add([tensor,attention_output])\n",
        "    tensor=self.layernorm(tensor)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "mzSAmiYD9AvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self,d_model,dff,dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq=tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff,activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(d_model),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "      ])\n",
        "    self.add=tf.keras.layers.Add()\n",
        "    self.layer_norm=tf.keras.layers.LayerNormalization()\n",
        "  def call(self,tensor):\n",
        "    tensor=self.add([tensor,self.seq(tensor)])\n",
        "    tensor=self.layer_norm(tensor)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "ecLQzrxq-DtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,d_model,num_heads,dff,dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.self_attention=GlobalSelfAttention(num_heads=num_heads,key_dim=d_model,dropout=dropout_rate)\n",
        "    self.ffn=FeedForward(d_model,dff)\n",
        "  def call(self,tensor):\n",
        "    tensor=self.self_attention(tensor)\n",
        "    tensor=self.ffn(tensor)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "r9-abGiIOr0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,num_layers,d_model,num_heads,dff,vocab_size,dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model=d_model\n",
        "    self.num_layers=num_layers\n",
        "\n",
        "    self.pos_embedding=PositionalEmbedding(vocab_size=vocab_size,d_model=d_model)\n",
        "    self.encoder_layers=[EncoderLayer(d_model=d_model,num_heads=num_heads,dff=dff,dropout_rate=dropout_rate) for _ in range(num_layers)]\n",
        "    self.dropout=tf.keras.layers.Dropout(dropout_rate)\n",
        "  def call(self,vec):\n",
        "    vec=self.pos_embedding(vec)\n",
        "    vec=self.dropout(vec)\n",
        "    for i in range(self.num_layers):\n",
        "      vec=self.encoder_layers[i](vec)\n",
        "    return vec"
      ],
      "metadata": {
        "id": "8mtg7WxTPHfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,d_model,num_heads,dff,dropout_rate=0.1):\n",
        "    super(DecoderLayer,self).__init__()\n",
        "    self.causal_self_attention=CausalSelfAttention(num_heads=num_heads,key_dim=d_model,dropout=dropout_rate)\n",
        "    self.cross_attention=CrossAttention(num_heads=num_heads,key_dim=d_model,dropout=dropout_rate)\n",
        "    self.ffn=FeedForward(d_model,dff)\n",
        "\n",
        "  def call(self,tensor,context):\n",
        "    tensor=self.causal_self_attention(tensor=tensor)\n",
        "    tensor=self.cross_attention(tensor=tensor,context=context)\n",
        "\n",
        "    self.last_attention_scores=self.cross_attention.last_attention_scores\n",
        "\n",
        "    tensor=self.ffn(tensor)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "3_gnSdgWlDL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,num_layers,d_model,num_heads,dff,vocab_size,dropout_rate=0.1):\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.d_model=d_model\n",
        "    self.num_layers=num_layers\n",
        "    self.pos_embedding=PositionalEmbedding(vocab_size=vocab_size,d_model=d_model)\n",
        "    self.dropout=tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers=[DecoderLayer(d_model=d_model,num_heads=num_heads,dff=dff,dropout_rate=dropout_rate) for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attention_scores=None\n",
        "\n",
        "  def call(self,tensor,context):\n",
        "    tensor=self.pos_embedding(tensor)\n",
        "    tensor=self.dropout(tensor)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      tensor=self.dec_layers[i](tensor,context)\n",
        "\n",
        "    self.last_attention_scores=self.dec_layers[-1].last_attention_scores\n",
        "\n",
        "    return tensor\n"
      ],
      "metadata": {
        "id": "ZNHlbQ8WliEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self,*,num_layers,d_model,num_heads,dff,input_vocab_size,target_vocab_size,dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder=Encoder(num_layers=num_layers,d_model=d_model,num_heads=num_heads,dff=dff,vocab_size=input_vocab_size,dropout_rate=dropout_rate)\n",
        "    self.decoder=Decoder(num_layers=num_layers,d_model=d_model,num_heads=num_heads,dff=dff,vocab_size=target_vocab_size,dropout_rate=dropout_rate)\n",
        "    self.final_layer=tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self,inputs):\n",
        "    context,input=inputs\n",
        "    context=self.encoder(context)\n",
        "    input=self.decoder(input,context)\n",
        "\n",
        "    logits=self.final_layer(input)\n",
        "\n",
        "    try:\n",
        "      del logits.__keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "E3bkYGR4pQkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "JVuV_kIUyvcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers=12\n",
        "d_model=256\n",
        "dff=512\n",
        "num_heads=8\n",
        "dropout_rate=0.1"
      ],
      "metadata": {
        "id": "zikCp37dyvHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Transformer(num_layers=num_layers,d_model=d_model,num_heads=num_heads,dff=dff,input_vocab_size=5000,target_vocab_size=5000,dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "mehLpwjSwIxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self,d_model,warmup_steps=6000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model=d_model\n",
        "    self.d_model=tf.cast(self.d_model,tf.float32)\n",
        "\n",
        "    self.warmup_steps=warmup_steps\n",
        "\n",
        "  def __call__(self,step):\n",
        "    step=tf.cast(step,dtype=tf.float32)\n",
        "    arg1=tf.math.rsqrt(step)\n",
        "    arg2=step*(self.warmup_steps**-2)\n",
        "    return tf.math.rsqrt(self.d_model)*tf.math.minimum(arg1,arg2)"
      ],
      "metadata": {
        "id": "imdlZZ2x-KpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=CustomSchedule(d_model)\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate,beta_1=0.9,beta_2=0.98,epsilon=1e-9)"
      ],
      "metadata": {
        "id": "oY4UlUJZd9S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and metrics"
      ],
      "metadata": {
        "id": "N_wNpf-JeULP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label,pred):\n",
        "  mask=label!=0\n",
        "  loss_object=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=\"none\")\n",
        "  loss=loss_object(label,pred)\n",
        "\n",
        "  mask=tf.cast(mask,dtype=loss.dtype)\n",
        "  loss*=mask\n",
        "\n",
        "  loss=tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred=tf.argmax(pred,axis=2)\n",
        "  label=tf.cast(label,pred.dtype)\n",
        "  matching=label==pred\n",
        "\n",
        "  mask=label!=0\n",
        "  matching=matching & mask\n",
        "\n",
        "  matching=tf.cast(matching,dtype=tf.float32)\n",
        "  mask=tf.cast(mask,dtype=tf.float32)\n",
        "  return tf.reduce_sum(matching)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "48IkKmkNeL2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "ob9z2T3uf8I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt=tf.keras.callbacks.ModelCheckpoint(\"punchline\",monitor=\"masked_accuracy\",save_best_only=True,save_weights_only=True)"
      ],
      "metadata": {
        "id": "Qu75Ifsif7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "T8vJYfO5gvOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=masked_loss,optimizer=optimizer,metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "sLyP84KAfrk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x=(X_train_vec,X_train_dec_vec),y=Y_train_vec,batch_size=32,epochs=15,callbacks=[model_ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4IUhyqfg61o",
        "outputId": "ade65fbb-39b2-4972-f4a4-9fa6f56272d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.5381 - masked_accuracy: 0.8839\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.5291 - masked_accuracy: 0.8858\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.5218 - masked_accuracy: 0.8870\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.5148 - masked_accuracy: 0.8887\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.5066 - masked_accuracy: 0.8905\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.5021 - masked_accuracy: 0.8906\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.4949 - masked_accuracy: 0.8925\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.4889 - masked_accuracy: 0.8942\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 92s 117ms/step - loss: 0.4850 - masked_accuracy: 0.8951\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.4742 - masked_accuracy: 0.8976\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 89s 113ms/step - loss: 0.4750 - masked_accuracy: 0.8975\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.4644 - masked_accuracy: 0.8997\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.4625 - masked_accuracy: 0.9000\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 92s 117ms/step - loss: 0.4531 - masked_accuracy: 0.9024\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 89s 114ms/step - loss: 0.4560 - masked_accuracy: 0.9016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('./09122300_checkpoints/09122300_checkpoint')"
      ],
      "metadata": {
        "id": "ON1Y4ypvhsdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r 09122300_checkpoints.zip 09122300_checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB5zm7fMrp9e",
        "outputId": "5ea413cd-6717-4ba7-da27-41045c0a125f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: 09122300_checkpoints/ (stored 0%)\n",
            "  adding: 09122300_checkpoints/09122300_checkpoint.data-00000-of-00001 (deflated 9%)\n",
            "  adding: 09122300_checkpoints/09122300_checkpoint.index (deflated 81%)\n",
            "  adding: 09122300_checkpoints/checkpoint (deflated 49%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"09122000_checkpoints.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bp0Qp370s053",
        "outputId": "50a595de-fed1-4fcf-8722-f74fa3efe298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bd8a7cbc-45ac-4919-81fe-a98e17d43215\", \"09122000_checkpoints.zip\", 941333275)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference using model"
      ],
      "metadata": {
        "id": "Cs_dKg8dzM0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy trained weights"
      ],
      "metadata": {
        "id": "5ZNMYWySKnjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 09122200_checkpoints.zip"
      ],
      "metadata": {
        "id": "JJZbDr-Is7ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3b5ac0-b660-4a93-c699-6c3bf3f0693e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open 09120228_checkpoints.zip, 09120228_checkpoints.zip.zip or 09120228_checkpoints.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"09122200_checkpoints/09122200_checkpoint\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7XStCgdM33b",
        "outputId": "d13cb88b-a42d-4e3e-ebf2-76e07fd05108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7d21280faf50>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run inference"
      ],
      "metadata": {
        "id": "QeM3VjIuNOCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Punchline(tf.Module):\n",
        "  def __init__(self,text_vec,model):\n",
        "    self.text_vec=text_vec\n",
        "    self.model=model\n",
        "    self.vocab_list=self.text_vec.get_vocabulary()\n",
        "\n",
        "  def __call__(self,sentence,max_length=30):\n",
        "    sentence=\"<sol> \"+sentence\n",
        "    sentence=self.text_vec(sentence)\n",
        "    sentence=sentence[tf.newaxis]\n",
        "\n",
        "    decoder_input=\"<sol>\"\n",
        "    decoder=self.text_vec(decoder_input)\n",
        "    decoder=decoder[tf.newaxis]\n",
        "\n",
        "    for i in range(max_length):\n",
        "      predictions=self.model([sentence,decoder],training=False)\n",
        "      result=tf.argmax(predictions,axis=-1)[0].numpy().tolist()\n",
        "      word=self.vocab_list[result[i]]\n",
        "\n",
        "      if word==\"eol\":\n",
        "        break\n",
        "\n",
        "      decoder_input=decoder_input+\" \"+word\n",
        "      decoder=self.text_vec(decoder_input)\n",
        "      decoder=decoder[tf.newaxis]\n",
        "\n",
        "    return decoder_input"
      ],
      "metadata": {
        "id": "zzPV9WMmNJwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punchline=Punchline(text_vec_layer,model)"
      ],
      "metadata": {
        "id": "dVYVARekaOd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"I'm doing good i'm on some new shit\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg7z-piWbcUf",
        "outputId": "1bd166c0-13bc-402a-b309-713367c3f0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> been saying yes instead of no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"When you look at me The whole world fade\"))"
      ],
      "metadata": {
        "id": "29zs8B_4b7gI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ca1b7f-ec41-4315-a8f6-46f91360949f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> if your love has [UNK] my name again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"It's like snow on the beach\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQGqqFHxKWNM",
        "outputId": "c1884e03-8684-4abb-c8e9-0ae0e183c05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> like snow on the beach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"Flying in a dream\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q52Lq71SKgms",
        "outputId": "d3653afd-8ee2-47eb-fe46-a56096f4feb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> stars by the pocketful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"The clouds are white on the blue sky\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPgVxj6NKmMv",
        "outputId": "1668fc65-79da-458e-a1a1-9b1df76bd6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> and were standing in the middle of the night\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"Walk down the country road\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDsH2O_BQxcz",
        "outputId": "852cff30-1569-4658-a9fb-3d1da39d94ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> almost there dont be lonely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"Empty bottles from sleepless nights\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naQAQ52qRH7G",
        "outputId": "c4a35201-26d3-4510-8f2e-e832de09c731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> theres a light in the sky\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"I promise you'll never find a person like me\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV_h4nvdSI_V",
        "outputId": "183af9dd-c866-4e0a-a238-6f599327bfe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> now you know that my name they got the floor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"When you think of me\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt0N6fNKTTZi",
        "outputId": "b80cb2fa-d1f1-4b10-f3b9-256140cb29cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> hes in the middle of the night\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"nice to meet you\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF9vhsCdgpA1",
        "outputId": "ae1cb088-d6ff-4cd7-e9b6-4ea566657a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> well i hope youre happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"where have you been\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awhu7ITYi3nM",
        "outputId": "fdd6680a-540f-4a20-f1c1-23c968ce5208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> now girl i gotta keep you waiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punchline(\"ayy ayy ayy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC1lo7YCkQg6",
        "outputId": "f09791ba-0f30-4b29-b15b-639e51909990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sol> bitch better have to keep you off\n"
          ]
        }
      ]
    }
  ]
}